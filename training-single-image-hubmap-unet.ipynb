{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport math\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport tifffile\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting images to lists\n\nImg = os.listdir('../input/hubmap-aaa6a05cc-256x256-tiles/images/Images_01')\n# print(Img)\n\nimg = []\n\nfor filename in Img:\n    if filename.endswith('.png'):\n        img.append(filename)\n    \nimg.sort()\nimg = img[:3000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting masks to lists\n\nMsk = os.listdir('../input/hubmap-aaa6a05cc-256x256-tiles/masks/masks_01')\n\nMask = []\n\nfor filename in Msk:\n    if filename.endswith('.png'):\n        Mask.append(filename)\n    \nMask.sort()\nMask = Mask[:3000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting list of Images and Mask into input 'shape'\n\ny = np.zeros((3000, 256, 256 , 1), dtype=np.float32)\nX = np.zeros((3000,256, 256, 1), dtype=np.float32)\n\nn = 0\nfor file in tqdm(img , total = X.shape[0]):\n    index = img.index(file)\n    dir_img = os.path.join('../input/hubmap-aaa6a05cc-256x256-tiles/images/Images_01/', file)\n    im = Image.open(dir_img)\n    im = im.resize((256, 256))\n    im = np.reshape(im.convert('L'), (256,256,1)) \n    X[n] = im\n    \n    mask = Mask[index]\n    dir_mask = os.path.join('../input/hubmap-aaa6a05cc-256x256-tiles/masks/masks_01/', mask)\n    mk = Image.open(dir_mask)\n    mk = mk.resize((256, 256))\n    mk = np.reshape(mk.convert('L'), (256,256,1)) \n    y[n] = mk\n    n += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/segmentation_models","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env SM_FRAMEWORK=tf.keras\n\nimport keras\nimport tensorflow as tf\nfrom segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom keras.models import model_from_json\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nfrom keras.layers import Input, Conv2D, Reshape\nfrom keras.models import Model\nfrom keras import backend as K","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split train data into train and test sets\n\ntrain_images, X_test, train_labels, y_test = train_test_split(X, y, test_size=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing 'train_images' for segmentation model\n\nBACKBONE = 'resnet34'\npreprocess_input = get_preprocessing(BACKBONE)\n\ntrain_images = preprocess_input(train_images)\ntrain_labels = preprocess_input(train_labels)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split train data into train and validation sets\n\nX_train, X_val, y_train, y_val = train_test_split(train_images, train_labels,\n                                                  test_size=0.15, random_state=22)\n\n#Preprocessing validation images for segmentation model\nX_val = preprocess_input(X_val)\ny_val = preprocess_input(y_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape , X_test.shape , X_val.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Building using U-net\n\nfrom keras.layers import Reshape\nN = X_train.shape[-1]\n\n# create the base pre-trained model\nbase_model = Unet(backbone_name='resnet34', encoder_weights='imagenet')\n\n# add a layer with defined input shape\ninput_base_model = Input(shape=(256, 256, N))\n\n# add a convolution layer with input data\nl1 = Conv2D(3, (1, 1))(input_base_model)\n\n# defining output layer shape\nout = base_model(l1)\n\n# x1 = Conv2D(10, kernel_size =3,strides=2,padding = \"same\", activation=\"relu\")(out)\n# x1 =layers.BatchNormalization()(x1)\n\n# x2= Conv2D(10, kernel_size=3,strides=2,padding = \"same\", activation=\"relu\")(x1)\n# x2 =layers.BatchNormalization()(x2)\n\n# x3 = Conv2D(10, kernel_size=3,strides=2,padding = \"same\", activation=\"relu\")(x2)\n# x3 =layers.BatchNormalization()(x3)\n\n# x4 = Conv2D(1, kernel_size=2,strides=2,padding = \"same\", activation=\"relu\")(x3)\n\n# x_out = Reshape((16,16))(x4)\n\nmodel = Model(input_base_model, out, name=base_model.name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks\n\nlr_schedule = keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 10))\n\ninitial_learning_rate = 0.01\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate,\n    decay_steps=100000,\n    decay_rate=0.96,\n    staircase=True)\n\n\nearly_stopping = keras.callbacks.EarlyStopping(patience=8 , verbose = 1)\n\nmodel_checkpoint = keras.callbacks.ModelCheckpoint(\n                   '/kaggle/working/best_cnn.h5', \n                   save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = keras.optimizers.Adam(learning_rate=lr_schedule, amsgrad=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining metrics and loss\n\ndef dice_coefficient(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n    denominator = tf.reduce_sum(y_true + y_pred)\n    return numerator / (denominator + tf.keras.backend.epsilon())\n\ndef loss(y_true, y_pred):\n    return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Compiling\n\nmodel.compile(optimizer = optimizer, loss=binary_crossentropy, metrics=[dice_coefficient])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\n\ndatagen = ImageDataGenerator(rotation_range=8,\n                             zoom_range=[0.95, 1.05],\n                             height_shift_range=0.10,\n                             shear_range=0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit model in order to determine best learning rate \n\nhistory = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n                                  epochs=30, \n                                  validation_data=(X_val, y_val),\n                                  callbacks=[early_stopping, model_checkpoint]\n                                 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# history = model.fit(X_train,y_train,batch_size=32,epochs=10,validation_data=(X_test, y_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.metrics_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir(history)","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dice_coefficient = history.history['dice_coefficient']\nval_dice_coefficient = history.history['val_dice_coefficient']\n\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(20, 10))\n\nplt.subplot(1, 2, 1)\nplt.plot(dice_coefficient, label='Dice coefficient')\nplt.plot(val_dice_coefficient, label='Validation Dice coefficient')\nplt.legend()\nplt.xlabel('Epochs')\nplt.title('Epochs vs. Training and Validation Dice coefficient')\n    \nplt.subplot(1, 2, 2)\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.title('Epochs vs. Training and Validation Loss')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Learning Rate vs. Loss\n\nplt.plot(history.epoch, history.history['loss'])\n# plt.axis([1e-4, 1e-1, 0, 4])\nplt.xlabel('Epochs')\nplt.ylabel('Training Loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}