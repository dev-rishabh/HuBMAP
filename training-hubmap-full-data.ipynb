{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install split-folders tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport math\nimport cv2\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport skimage.io\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport zipfile\nimport tifffile\nimport matplotlib.pyplot as plt\n\nimport splitfolders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making output directories\n\nos.mkdir('./Images')\nos.mkdir('./Masks')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitfolders.ratio(\"../input/copy-of-iafoss-dataset-256x256/train\", output=\"./Images\", seed=1337, ratio=(.8, .1, .1), group_prefix=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splitfolders.ratio(\"../input/copy-of-iafoss-dataset-256x256/masks\", output=\"./Masks\", seed=1337, ratio=(.8, .1, .1), group_prefix=None)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('./Images/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nlist = os.listdir('./Images/train/Images_01') # dir is your directory path\nnumber_files1 = len(list)\nprint(number_files1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/segmentation_models","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env SM_FRAMEWORK=tf.keras\n\nimport keras\nimport tensorflow as tf\nfrom segmentation_models import Unet\nfrom segmentation_models import get_preprocessing\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.losses import dice_loss\nfrom segmentation_models.metrics import iou_score\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom keras.models import model_from_json\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import LearningRateScheduler\n\nfrom keras.layers import Input, Conv2D, Reshape\nfrom keras.models import Model\nfrom keras import backend as K","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preprocessing 'train_images' for segmentation model\n\nBACKBONE = 'resnet34'\npreprocess_input = get_preprocessing(BACKBONE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen_args = dict(\n#     featurewise_center=True,\n#                      featurewise_std_normalization=True,\n                     rotation_range=90,\n                     width_shift_range=0.1,\n                     height_shift_range=0.1,\n                     zoom_range=0.2)\n\nimage_datagen = preprocess_input(ImageDataGenerator(**data_gen_args))\nmask_datagen = preprocess_input(ImageDataGenerator(**data_gen_args))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Provide the same seed and keyword arguments to the fit and flow methods\nseed = 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image_generator = image_datagen.flow_from_directory(\n    './Images/train',\n    class_mode=None,\n    batch_size=32,\n    seed=seed)\ntrain_mask_generator = mask_datagen.flow_from_directory(\n    './Masks/train',\n    class_mode=None,\n    batch_size=32,\n    seed=seed)\n\n# combine generators into one which yields image and masks\ntrain_generator = zip(train_image_generator, train_mask_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_image_generator = image_datagen.flow_from_directory(\n    './Images/val',\n    class_mode=None,\n    batch_size=32,\n    seed=seed)\nvalidation_mask_generator = mask_datagen.flow_from_directory(\n    './Masks/val',\n    class_mode=None,\n    batch_size=32,\n    seed=seed)\n\n# combine generators into one which yields image and masks\nvalidation_generator = zip(validation_image_generator, validation_mask_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Building using U-net\n\nfrom keras.layers import Reshape\n\n# create the base pre-trained model\nbase_model = Unet(backbone_name='resnet34', encoder_weights='imagenet')\n\n# add a layer with defined input shape\ninput_base_model = Input(shape=(256, 256, 3))\n\n# add a convolution layer with input data\nl1 = Conv2D(3, (1, 1))(input_base_model)\n\n# defining output layer shape\nout = base_model(l1)\n\nmodel = Model(input_base_model, out, name=base_model.name)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# callbacks\n\nlr_schedule = keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch / 10))\n\nlr_check = keras.callbacks.ReduceLROnPlateau(patience = 4)\n\n# initial_learning_rate = 0.01\n# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n#     initial_learning_rate,\n#     decay_steps=100000,\n#     decay_rate=0.96,\n#     staircase=True)\n\n\nearly_stopping = keras.callbacks.EarlyStopping(patience=8 , verbose = 1)\n\nmodel_checkpoint = keras.callbacks.ModelCheckpoint(\n                   '/kaggle/working/best_cnn.h5', \n                   save_best_only=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = keras.optimizers.Adam(learning_rate=0.0001, amsgrad=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Defining metrics and loss\n\ndef dice_coefficient(y_true, y_pred):\n    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n    denominator = tf.reduce_sum(y_true + y_pred)\n    return numerator / (denominator + tf.keras.backend.epsilon())\n\n# def loss(y_true, y_pred):\n#     return binary_crossentropy(y_true, y_pred) - tf.math.log(dice_coefficient(y_true, y_pred) + tf.keras.backend.epsilon())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Compiling\n\nmodel.compile(optimizer = optimizer, loss=dice_loss, metrics=[dice_coefficient])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data augmentation\n\ndatagen = ImageDataGenerator(rotation_range=8,\n                             zoom_range=[0.95, 1.05],\n                             height_shift_range=0.10,\n                             shear_range=0.15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fit model in order to determine best learning rate \n\nhistory = model.fit(train_generator,steps_per_epoch = 32,\n                                  epochs=30, \n                                  validation_data=validation_generator,\n                                  validation_steps = 8,\n                                  callbacks=[lr_check, early_stopping, model_checkpoint]\n                                 )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_image_generator = image_datagen.flow_from_directory(\n    './Images/test',\n    class_mode=None,\n    batch_size = 32,\n    seed=seed)\ntest_mask_generator = mask_datagen.flow_from_directory(\n    './Masks/test',\n    class_mode=None,\n    batch_size = 32,\n    seed=seed)\n\ntest_generator = zip (test_image_generator , test_mask_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_generator)\n\n# not working","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.metrics_names","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dice_coefficient = history.history['dice_coefficient']\nval_dice_coefficient = history.history['val_dice_coefficient']\n\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nplt.figure(figsize=(20, 10))\n\nplt.subplot(1, 2, 1)\nplt.plot(dice_coefficient, label='Dice coefficient')\nplt.plot(val_dice_coefficient, label='Validation Dice coefficient')\nplt.legend()\nplt.xlabel('Epochs')\nplt.title('Epochs vs. Training and Validation Dice coefficient')\n    \nplt.subplot(1, 2, 2)\nplt.plot(train_loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.title('Epochs vs. Training and Validation Loss')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot Learning Rate vs. Loss\n\nplt.plot(history.epoch, history.history['loss'])\n# plt.axis([1e-4, 1e-1, 0, 4])\nplt.xlabel('Epochs')\nplt.ylabel('Training Loss')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}